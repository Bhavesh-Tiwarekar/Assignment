{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa271b0b-f541-47eb-830b-103157c94454",
   "metadata": {},
   "source": [
    "#### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b91b98d-709a-4a06-bf09-60ae30ac3521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\n\\na. Web Scrapping and its usage:\\n    1. Web scraping refers to the process of extracting information and data from websites.\\n    2. It involves retrieving specific data from web pages, such as text, images, tables, links, etc.\\n    3. It is used for data collecton and aggregation, research and analysis, price monitoring, academic reserarch, etc.\\nb. Three areas where Web Scraping is used to get data:\\n    1. E-Commerce and Price Comparison:\\n        Businesses can extract product details, prices, availability, and customer reviews to optimise  their own pricing strategies, and ensure they remain \\n        competitive in the market. \\n    2. Social Media and Sentiment Analysis:\\n        By analyzing social media posts and comments, businesses can gauge how customers feel about their products or services and make informed decisions \\n        based on these insights.\\n    3. Financial and Investment Analysis: \\n        Web scraping is widely used in the financial sector to gather real-time financial data, stock prices, market trends and news from various \\n        financial websites. This data is essential for traders, investors, and financial analysts to make informed investment decisions, develop \\n        trading algorithms, and track market performance. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "a. Web Scrapping and its usage:\n",
    "    1. Web scraping refers to the process of extracting information and data from websites.\n",
    "    2. It involves retrieving specific data from web pages, such as text, images, tables, links, etc.\n",
    "    3. It is used for data collecton and aggregation, research and analysis, price monitoring, academic reserarch, etc.\n",
    "b. Three areas where Web Scraping is used to get data:\n",
    "    1. E-Commerce and Price Comparison:\n",
    "        Businesses can extract product details, prices, availability, and customer reviews to optimise  their own pricing strategies, and ensure they remain \n",
    "        competitive in the market. \n",
    "    2. Social Media and Sentiment Analysis:\n",
    "        By analyzing social media posts and comments, businesses can gauge how customers feel about their products or services and make informed decisions \n",
    "        based on these insights.\n",
    "    3. Financial and Investment Analysis: \n",
    "        Web scraping is widely used in the financial sector to gather real-time financial data, stock prices, market trends and news from various \n",
    "        financial websites. This data is essential for traders, investors, and financial analysts to make informed investment decisions, develop \n",
    "        trading algorithms, and track market performance. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53efca61-f6a0-484c-a74c-bbf1a8cf1d7c",
   "metadata": {},
   "source": [
    "#### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e26ddc-13e8-48f2-acc6-dbdcdd02a9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\n\\nThe most common methods used for Web Scraping are:\\n1. Manual copy-and-paste.\\n2. Text pattern matching.\\n3. HTTP programming.\\n4. HTML parsing.\\n5. Web Scraping Libraries and Frameworks.\\n6. XPath.\\n7. DOM Parsing.\\n8. Computer vision web-page analysis.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "The most common methods used for Web Scraping are:\n",
    "1. Manual copy-and-paste.\n",
    "2. Text pattern matching.\n",
    "3. HTTP programming.\n",
    "4. HTML parsing.\n",
    "5. Web Scraping Libraries and Frameworks.\n",
    "6. XPath.\n",
    "7. DOM Parsing.\n",
    "8. Computer vision web-page analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772aa76-00ec-4a04-9798-a18dd8cd390c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ccea3a-0f6d-4e83-a3da-da37cb56f201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\n\\n1. Beautiful Soup is a Python library that makes it easy to scrape information from web pages. \\n2. It is a python package which allows us to pull data out of HTML and XML documents.\\n3. It is commonly used for data mining and data analysis.\\n4. It helps in the navigation of DOM tree using CSS selectors.\\n5. Beautiful Soup is often used in combination with the requests library to first fetch web page content and then parse it using Beautiful Soup.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "1. Beautiful Soup is a Python library that makes it easy to scrape information from web pages. \n",
    "2. It is a python package which allows us to pull data out of HTML and XML documents.\n",
    "3. It is commonly used for data mining and data analysis.\n",
    "4. It helps in the navigation of DOM tree using CSS selectors.\n",
    "5. Beautiful Soup is often used in combination with the requests library to first fetch web page content and then parse it using Beautiful Soup.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14d356f-129c-43b7-ac12-9e4bd0f900f9",
   "metadata": {},
   "source": [
    "#### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a528ea8-6a06-4001-8094-88e403d223eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\n\\nThe following are some of the reasons for using flask in web scraping project:\\n    1. Flask helps to interact with the web scraping functionality by creating an interface where user can specify scraping parameters or input to forms.\\n    2. The Flask can store scraped data in a database like MongoDB.\\n    3. Flask can incorporate error handling mechanisms and logging features to ensure that the web scraping process is robust and can handle unexpected scenarios.\\n    4. Flask can be easily deployed to web servers and cloud platforms, allowing you to make the web scraping project accessible over the internet. \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "The following are some of the reasons for using flask in web scraping project:\n",
    "    1. Flask helps to interact with the web scraping functionality by creating an interface where user can specify scraping parameters or input to forms.\n",
    "    2. The Flask can store scraped data in a database like MongoDB.\n",
    "    3. Flask can incorporate error handling mechanisms and logging features to ensure that the web scraping process is robust and can handle unexpected scenarios.\n",
    "    4. Flask can be easily deployed to web servers and cloud platforms, allowing you to make the web scraping project accessible over the internet. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd67244-9e0a-4142-8a98-f802c58e3c49",
   "metadata": {},
   "source": [
    "#### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47300f76-6810-4492-ba6d-58c37a9fc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Answer:\n",
    "\n",
    "1. AWS CodePipeline and Elastic Beanstalk are the services used in the web scraping project.\n",
    "2. CodePipeline is a Continuous Integration and Continuous Delivery (CI/CD) service that automates the process of building, testing, and deploying applications.\n",
    "3. It integrates with various AWS services and third-party tools to manage the entire software release process, including source code repositories, \n",
    "   build providers, testing tools, and deployment services.\n",
    "4. Elastic Beanstalk is a Platform as a Service (PaaS) that simplifies the deployment, management, and scaling of applications.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
